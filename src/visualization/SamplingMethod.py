
import numpy as np
from matplotlib import pyplot as plt
import logging
import sys

from numpy._typing import NDArray
from src.data_processing.SampleEstimator import SampleEstimator
from src.data_processing.SampleTester import SampleTester
from visualization import GraphEstimates
import src.visualization.Metrics as metrics
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)],
)


def investigate_tester_rank_constraint(*, imageSet: NDArray, imageProductType: str, sampleSize: int, testSize: int,
                                       testPrefix: str, startingConstr: int, endingConstr: int, increment=1, specifiedKArr=None, plotFrob=True):
    """
    :param specifiedKArr: value of k for the k neighbour score
    :param imageSet: Set of images used to the test and sample image sets. Currently, the training set takes from the front
    of the image set, and the test set takes from the tail of the image set TODO Do a proper monte carlo simulation.
    :param imageProductType: Image product type to investigate
    :param startingConstr: Starting lowest rank constraint to start the sweep inclusive
    :param endingConstr: Final largest rank constraint to end the sweep inclusive
    :param increment: Increment in the rank constraint sweep
    :param testPrefix: Used as a prefix to all the test names
    :param testSize: Size of the test set
    :param sampleSize: Size of the sample set
    :param plotFrob: If True, also plots frob error against rank
    :return: Uses the penncorr method to generate embeddings for different rank constraints
    Makes a graph of the average neighbour score against rank_constraint and
    average frobenius distance against rank_constraint
    Remember to use plt.show() to display plots

    Aims to answer the question: How does the rank constraint affect the error of the embeddings generated by penncorr?
    """
    if startingConstr >= endingConstr:
        raise ValueError("Starting rank constraint must be lower than ending constraint")
    if specifiedKArr is None:
        specifiedKArr = [5]

    aveFrobDistanceArr = []
    # A list of k neighbour plotting data, for each of the k in specified K array
    allAveNeighArr = [[] for i in specifiedKArr]
    rankConstraints = list(range(startingConstr, endingConstr + 1, increment))

    # For each rank in the sweep, generate a SampleTester and add its results to the array
    for rank in rankConstraints:
        logging.info("Investigating rank " + str(rank) + " of " + str(endingConstr))
        embType = "pencorr_" + str(rank)
        sampleName = testPrefix + "_sample_" + str(rank) + " of " + str(endingConstr)
        testName = testPrefix + "_test_" + str(rank) + " of " + str(endingConstr)

        # Taking training samples from the front of the image array
        trainingSample = imageSet[:sampleSize]

        # Taking testing samples from the back of the image array
        testSample = imageSet[-testSize:]

        # Generating a sampleEstimator and SampleTester with the input parameters
        sampleEstimator = SampleEstimator(sampleName=sampleName, trainingImageSet=trainingSample, embeddingType=embType,
                                          imageProductType=imageProductType)
        sampleTester = SampleTester(testImages=testSample, sampleEstimator=sampleEstimator, testName=testName)


        # For each k to be investigated, append the respective k neighbour score
        for i in range(len(specifiedKArr)):
            k = specifiedKArr[i]
            allAveNeighArr[i].append(metrics.get_mean_normed_k_neighbour_score(sampleTester.matrixG,
                                                                               sampleTester.matrixGprime, k))
        aveFrobDistanceArr.append(sampleTester.aveFrobDistance)

    if plotFrob:
        rankFig, axArr = plt.subplots(1, len(specifiedKArr) + 1)
        frobAx = axArr[-1]
        neighAx = axArr[:-1]
        GraphEstimates.plot_frob_error_against_rank_constraint(frobAx, rankConstraints, aveFrobDistanceArr)
    else:
        rankFig, neighAx = plt.subplots(1, len(specifiedKArr))
    GraphEstimates.plot_error_against_rank_constraint(neighAx, rankConstraints, allAveNeighArr, specifiedKArr)



def investigate_training_size(*, imageSet: NDArray, imageProductType: str, embeddingType:str, startingTrainingSize: int,
                              endingTrainingSize: int, increment=50, testSize: int,
                              testPrefix: str, specifiedKArr=None, plotFrob=True):
    """
    :param imageSet: Set of images used to the test and sample image sets. Currently, the training set takes from the front
    of the image set, and the test set takes from the tail of the image set TODO Do a proper monte carlo simulation.
    :param imageProductType: Image product type to investigate
    :param embeddingType: Embedding type to investigate
    :param startingTrainingSize: Starting point for the sweep (inclusive)
    :param endingTrainingSize: Ending point for the sweep
    :param increment: Increment in the sweep
    :param testSize: Size of the test set
    :param testPrefix: Prefix to the test names
    :param specifiedKArr: Specified k to plot for the neighbour graphs
    :param plotFrob: If true, also plot the frob error against sample size
    :return: Generates a graph for the k neighbour score against the size of the test sample.
    For now, training set is obtained from the start of imageSet and testing from the end of imageSet.
    IMPORTANT: Hence as the sample size increases, the training set remains mostly the same, and new images are added
    """
    if startingTrainingSize > endingTrainingSize:
        raise ValueError("Starting sample size must be lower than ending")
    sampleSizeArr = list(range(startingTrainingSize, endingTrainingSize, increment))
    # A list of k neighbour plotting data, for each of the k in specified K array
    allAveNeighArr = [[] for i in specifiedKArr]
    aveFrobDistanceArr = []
    for sampleSizeTested in sampleSizeArr:
        logging.info("Investigating sample size " + str(sampleSizeTested) + " of " + str(endingTrainingSize))

        sampleName = testPrefix + "_sample_" + str(sampleSizeTested) + " of " + str(endingTrainingSize)
        testName = testPrefix + "_test_" + str(sampleSizeTested) + " of " + str(endingTrainingSize)


        # Taking training samples from the front of the image array
        trainingSample = imageSet[:sampleSizeTested]

        # Taking testing samples from the back of the image array
        testSample = imageSet[-testSize:]

        sampleEstimator = SampleEstimator(sampleName=sampleName, trainingImageSet=trainingSample,
                                          embeddingType=embeddingType, imageProductType=imageProductType)
        sampleTester = SampleTester(testImages=testSample, sampleEstimator=sampleEstimator, testName=testName)

        # For each value of k, add the result to the array
        for i in range(len(specifiedKArr)):
            k = specifiedKArr[i]
            allAveNeighArr[i].append(metrics.get_mean_normed_k_neighbour_score(sampleTester.matrixG,
                                                                               sampleTester.matrixGprime, k))
        aveFrobDistanceArr.append(sampleTester.aveFrobDistance)

    if plotFrob:
        trainingFig, axArr = plt.subplots(1, len(specifiedKArr) + 1)
        frobAx = axArr[-1]
        neighAx = axArr[:-1]
        GraphEstimates.plot_frob_error_against_training_size(frobAx, sampleSizeArr, aveFrobDistanceArr)
    else:
        trainingFig, neighAx = plt.subplots(1, len(specifiedKArr))
    GraphEstimates.plot_error_against_sample_size(neighAx, sampleSizeArr, allAveNeighArr, specifiedKArr)


